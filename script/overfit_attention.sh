python -m nmt.nmt.nmt \
    --attention=scaled_luong \
    --src=complex --tgt=simple \
    --vocab_prefix=data/PWKP/vocab  \
    --train_prefix=data/PWKP/val\
    --dev_prefix=data/PWKP/test\
    --test_prefix=data/PWKP/test\
    --out_dir=data/PWKP/overfit_attention_model \
    --num_train_steps=10000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu
